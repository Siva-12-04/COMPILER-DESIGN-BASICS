#include <stdio.h>
#include <string.h>
#include <ctype.h>

#define MAX_TOKEN_LENGTH 100

const char *keywords[] = {"int", "float", "if", "else", "while", "return", "for"};
const int num_keywords = 7;

const char *operators[] = {"+", "-", "*", "/", "=", "==", "<", ">", "<=", ">=", "!="};
const int num_operators = 10;

int is_keyword(char *token) {
    for (int i = 0; i < num_keywords; i++) {
        if (strcmp(token, keywords[i]) == 0) {
            return 1; 
        }
    }
    return 0; // 
}

int is_operator(char *token) {
    for (int i = 0; i < num_operators; i++) {
        if (strcmp(token, operators[i]) == 0) {
            return 1; // It is an operator
        }
    }
    return 0; // It is not an operator
}

int is_identifier(char *token) {
    if (isalpha(token[0]) || token[0] == '_') {  // Identifier must start with a letter or underscore
        for (int i = 1; token[i] != '\0'; i++) {
            if (!isalnum(token[i]) && token[i] != '_') {
                return 0; 
            }
        }
        return 1; 
    }
    return 0; 
}

void classify_token(char *token) {
    if (is_keyword(token)) {
        printf("Token: %s | Type: Keyword\n", token);
    } else if (is_operator(token)) {
        printf("Token: %s | Type: Operator\n", token);
    } else if (is_identifier(token)) {
        printf("Token: %s | Type: Identifier\n", token);
    } else if (isdigit(token[0])) {
        printf("Token: %s | Type: Number\n", token);
    } else {
        printf("Token: %s | Type: Unknown\n", token);
    }
}

void lexical_analyzer(FILE *input_file) {
    char token[MAX_TOKEN_LENGTH];
    int i = 0;
    char ch;

    while ((ch = fgetc(input_file)) != EOF) {
        if (isalnum(ch) || ch == '_') { 
            token[i++] = ch;
        } else {
            if (i > 0) { // If token is formed, classify it
                token[i] = '\0';
                classify_token(token);
                i = 0; 
            }
            
            if (ch == ' ' || ch == '\n' || ch == '\t') {
                continue; 
            } else {
                token[0] = ch;
                token[1] = '\0';
                classify_token(token);
            }
        }
    }

    if (i > 0) { 
        token[i] = '\0';
        classify_token(token);
    }
}

int main() {
    FILE *input_file = fopen("sample_input.txt", "r");

    if (input_file == NULL) {
        printf("Error opening file.\n");
        return 1;
    }

    lexical_analyzer(input_file);

    fclose(input_file);

    return 0;
}
